{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pf8w4W1dU1B5",
        "outputId": "51df0991-3530-4319-be20-50fae6f9bd21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Found 371 validated image filenames.\n",
            "Found 42 validated image filenames.\n",
            "Found 103 validated image filenames.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n",
            "Epoch 1/15\n",
            "18/18 [==============================] - 246s 14s/step - loss: 2.4537 - mean_absolute_error: 1.2895 - val_loss: 1.3699 - val_mean_absolute_error: 0.9205\n",
            "Epoch 2/15\n",
            "18/18 [==============================] - 243s 14s/step - loss: 1.7059 - mean_absolute_error: 1.0903 - val_loss: 1.1604 - val_mean_absolute_error: 0.8321\n",
            "Epoch 3/15\n",
            "18/18 [==============================] - 241s 14s/step - loss: 1.5376 - mean_absolute_error: 1.0399 - val_loss: 1.0417 - val_mean_absolute_error: 0.7972\n",
            "Epoch 4/15\n",
            "18/18 [==============================] - 243s 14s/step - loss: 1.4705 - mean_absolute_error: 0.9994 - val_loss: 1.1135 - val_mean_absolute_error: 0.8177\n",
            "Epoch 5/15\n",
            "18/18 [==============================] - 246s 14s/step - loss: 1.4480 - mean_absolute_error: 0.9753 - val_loss: 0.9129 - val_mean_absolute_error: 0.7711\n",
            "Epoch 6/15\n",
            "18/18 [==============================] - 246s 14s/step - loss: 1.3997 - mean_absolute_error: 0.9801 - val_loss: 0.8324 - val_mean_absolute_error: 0.7271\n",
            "Epoch 7/15\n",
            "18/18 [==============================] - 254s 14s/step - loss: 1.3714 - mean_absolute_error: 0.9538 - val_loss: 0.7793 - val_mean_absolute_error: 0.6886\n",
            "Epoch 8/15\n",
            "18/18 [==============================] - 257s 14s/step - loss: 1.3537 - mean_absolute_error: 0.9634 - val_loss: 0.7521 - val_mean_absolute_error: 0.6409\n",
            "Epoch 9/15\n",
            "18/18 [==============================] - 254s 15s/step - loss: 1.2390 - mean_absolute_error: 0.9117 - val_loss: 0.7474 - val_mean_absolute_error: 0.6766\n",
            "Epoch 10/15\n",
            "18/18 [==============================] - 256s 14s/step - loss: 1.2814 - mean_absolute_error: 0.9135 - val_loss: 0.6099 - val_mean_absolute_error: 0.5662\n",
            "Epoch 11/15\n",
            "18/18 [==============================] - 263s 15s/step - loss: 1.2381 - mean_absolute_error: 0.9085 - val_loss: 0.6977 - val_mean_absolute_error: 0.6240\n",
            "Epoch 12/15\n",
            "18/18 [==============================] - 256s 14s/step - loss: 1.1993 - mean_absolute_error: 0.8701 - val_loss: 0.6664 - val_mean_absolute_error: 0.6270\n",
            "Epoch 13/15\n",
            "18/18 [==============================] - 259s 14s/step - loss: 1.3158 - mean_absolute_error: 0.9258 - val_loss: 1.0282 - val_mean_absolute_error: 0.7737\n",
            "Epoch 14/15\n",
            "18/18 [==============================] - 249s 14s/step - loss: 1.2282 - mean_absolute_error: 0.8937 - val_loss: 0.5717 - val_mean_absolute_error: 0.5498\n",
            "Epoch 15/15\n",
            "18/18 [==============================] - 249s 14s/step - loss: 1.2502 - mean_absolute_error: 0.9078 - val_loss: 0.7018 - val_mean_absolute_error: 0.5980\n",
            "6/6 [==============================] - 62s 10s/step - loss: 1.5595 - mean_absolute_error: 1.0390\n",
            "6/6 [==============================] - 61s 10s/step\n",
            "Accuracy within error margin 0.5: 28.16%\n",
            "     True Labels  Predicted Labels     Error\n",
            "0             -3         -2.209678  0.790322\n",
            "1             -3         -2.261961  0.738039\n",
            "2             -2         -1.079236  0.920764\n",
            "3             -3         -1.443832  1.556168\n",
            "4             -2         -2.010729  0.010729\n",
            "..           ...               ...       ...\n",
            "98            -1         -1.760997  0.760997\n",
            "99             0         -1.108499  1.108499\n",
            "100           -2         -2.305311  0.305311\n",
            "101           -2         -1.694834  0.305166\n",
            "102           -2         -0.956962  1.043038\n",
            "\n",
            "[103 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set directory paths to your training and testing data\n",
        "train_dir = '/content/drive/MyDrive/Machine_Learning/Project_5/Train'\n",
        "test_dir = '/content/drive/MyDrive/Machine_Learning/Project_5/Test'\n",
        "\n",
        "# Prepare labels and file paths from the filenames\n",
        "def prepare_labels_and_files(directory):\n",
        "    files = os.listdir(directory)\n",
        "    labels = [int(f.split('_')[-1].split('.')[0]) for f in files]\n",
        "    file_paths = [os.path.join(directory, f) for f in files]\n",
        "    return file_paths, labels\n",
        "\n",
        "train_files, train_labels = prepare_labels_and_files(train_dir)\n",
        "test_files, test_labels = prepare_labels_and_files(test_dir)\n",
        "\n",
        "# Split train files for validation\n",
        "train_files, val_files, train_labels, val_labels = train_test_split(train_files, train_labels, test_size=0.1, random_state=42)\n",
        "\n",
        "# Create dataframe for Keras\n",
        "train_df = pd.DataFrame({'filename': train_files, 'label': train_labels})\n",
        "val_df = pd.DataFrame({'filename': val_files, 'label': val_labels})\n",
        "test_df = pd.DataFrame({'filename': test_files, 'label': test_labels})\n",
        "\n",
        "# Image generators\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    horizontal_flip=True,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Create generators\n",
        "batch_size = 20\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    x_col='filename',\n",
        "    y_col='label',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='raw'\n",
        ")\n",
        "\n",
        "val_generator = test_datagen.flow_from_dataframe(\n",
        "    dataframe=val_df,\n",
        "    x_col='filename',\n",
        "    y_col='label',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='raw'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_dataframe(\n",
        "    dataframe=test_df,\n",
        "    x_col='filename',\n",
        "    y_col='label',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='raw',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Load the VGG16 model for transfer learning\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze all layers of the base model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add custom layers for regression on top of the base model\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "output = Dense(1)(x)  # Regression output\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error', metrics=['mean_absolute_error'])\n",
        "\n",
        "# Train the model\n",
        "epochs = 15  # Replace with the number of epochs we want\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=len(train_df) // batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=len(val_df) // batch_size\n",
        ")\n",
        "\n",
        "# Evaluate the model on test data\n",
        "test_steps_per_epoch = np.ceil(len(test_df) / batch_size)\n",
        "test_loss, test_mae = model.evaluate(test_generator, steps=test_steps_per_epoch)\n",
        "\n",
        "# Predicting on the test set\n",
        "test_predictions = model.predict(test_generator, steps=test_steps_per_epoch)\n",
        "\n",
        "# Ensure we have the same number of predictions as there are in the test set\n",
        "assert len(test_predictions) == len(test_df), \"Mismatch in number of predictions\"\n",
        "\n",
        "# Calculate accuracy based on an acceptable error margin\n",
        "error_margin = 0.5  # Define your error margin\n",
        "accurate_predictions = np.abs(test_df['label'].values - test_predictions.flatten()) <= error_margin\n",
        "accuracy = np.mean(accurate_predictions)\n",
        "\n",
        "# Print out the accuracy\n",
        "print(f'Accuracy within error margin {error_margin}: {accuracy:.2%}')\n",
        "\n",
        "# Create a dataframe to show results more clearly\n",
        "results_df = pd.DataFrame({\n",
        "    'True Labels': test_df['label'].values,\n",
        "    'Predicted Labels': test_predictions.flatten(),\n",
        "    'Error': np.abs(test_df['label'].values - test_predictions.flatten())\n",
        "})\n",
        "\n",
        "print(results_df)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}